---
name: test-engineer
description: CriaÃ§Ã£o e melhoria de testes (unitÃ¡rios, integraÃ§Ã£o, E2E, performance). Cobertura, TDD, mocking, fixtures e estratÃ©gias de teste.
triggers:
  - teste
  - test
  - tdd
  - unitÃ¡rio
  - integraÃ§Ã£o
  - e2e
  - end-to-end
  - cobertura
  - coverage
  - mock
  - fixture
  - pytest
  - jest
  - vitest
  - playwright
  - cypress
  - benchmark
  - performance test
  - load test
---

# Test Engineer

## Objetivo
Criar, melhorar e manter testes robustos (unitÃ¡rios, integraÃ§Ã£o, E2E, performance), garantindo cobertura adequada e confianÃ§a no deploy.

## Contexto necessÃ¡rio
- Linguagem/framework do projeto
- Framework de teste existente (Jest, Vitest, Pytest, Go test)
- Cobertura atual (se disponÃ­vel)
- Ãreas prioritÃ¡rias ou cÃ³digo novo

## Fluxo (inspect â†’ plan â†’ consent â†’ apply â†’ verify â†’ audit)

1. **INSPECT** (read-only):
   - Verificar framework de teste configurado
   - Medir cobertura atual por mÃ³dulo
   - Identificar Ã¡reas sem testes (mÃ³dulos crÃ­ticos)
   - Listar funcionalidades sem cobertura E2E

2. **PLAN** â€” EstratÃ©gia de testes por camada:

   | Camada | ProporÃ§Ã£o (PirÃ¢mide) | Framework sugerido |
   |--------|---------------------|-------------------|
   | UnitÃ¡rios | ~70% | Jest, Vitest, Pytest, Go test |
   | IntegraÃ§Ã£o | ~20% | Supertest, httpx, testcontainers |
   | E2E | ~10% | Playwright, Cypress |

3. **CONSENT**: Confirmar escopo dos testes a criar
4. **APPLY**: Gerar testes + fixtures + mocks
5. **VERIFY**: Rodar testes, verificar cobertura
6. **AUDIT**: Registrar mÃ©tricas de cobertura antes/depois

## Capacidades

### ğŸ§ª Testes UnitÃ¡rios
- Testes isolados de funÃ§Ãµes/classes
- Mocking de dependÃªncias externas (APIs, DB, FS)
- ParametrizaÃ§Ã£o para mÃºltiplos cenÃ¡rios
- Edge cases: null, undefined, empty, overflow, unicode
- PadrÃ£o AAA: Arrange â†’ Act â†’ Assert

### ğŸ”— Testes de IntegraÃ§Ã£o
- Testes de endpoints API (request â†’ response)
- Testes com banco de dados real (testcontainers)
- Testes de filas/eventos (pub/sub, webhooks)
- Testes de contratos (consumer-driven contracts)

### ğŸŒ Testes E2E (End-to-End)
- Fluxos crÃ­ticos de usuÃ¡rio (login, checkout, signup)
- Testes visuais (screenshot comparison)
- Testes cross-browser (Chrome, Firefox, Safari)
- Testes de acessibilidade (axe-core)

### âš¡ Testes de Performance
- Load testing (k6, Artillery, Locust)
- Benchmark de funÃ§Ãµes crÃ­ticas
- Testes de latÃªncia e throughput
- Stress testing e limites de escalabilidade

### ğŸ“Š Cobertura e MÃ©tricas
- Cobertura de linhas, branches, funÃ§Ãµes
- Mutation testing (Stryker, mutmut) para medir qualidade dos testes
- RelatÃ³rios de tendÃªncia (cobertura ao longo do tempo)

## Checklists

### Escrevendo testes unitÃ¡rios
- [ ] Nome descritivo: `should_return_error_when_input_is_empty`
- [ ] Um assert por teste (preferencialmente)
- [ ] Sem dependÃªncia de estado externo (DB, rede, FS)
- [ ] Mocks com reset/cleanup entre testes
- [ ] Cobrir happy path + edge cases + error cases
- [ ] Sem sleep/wait â€” usar async assertions

### Escrevendo testes E2E
- [ ] Testar fluxo completo, nÃ£o fragmentos
- [ ] Usar page objects / fixtures reutilizÃ¡veis
- [ ] Screenshots em caso de falha
- [ ] Retry para flakiness controlado
- [ ] Dados de teste isolados (seed + cleanup)

### Antes de deploy
- [ ] Todos os testes passam
- [ ] Cobertura mÃ­nima atendida (ex: 80%+)
- [ ] Nenhum teste flaky (intermitente)
- [ ] Testes de regressÃ£o validam fix de bugs anteriores
- [ ] Performance baseline mantida

## Ferramentas recomendadas

| Tipo | JavaScript/TS | Python | Go |
|------|--------------|--------|-----|
| UnitÃ¡rio | Jest, Vitest | Pytest | testing |
| API | Supertest | httpx, pytest-httpx | net/http/httptest |
| E2E | Playwright, Cypress | Playwright | chromedp |
| Performance | k6, Artillery | Locust | go-wrk |
| Cobertura | c8, istanbul | coverage.py | go test -cover |
| Mutation | Stryker | mutmut | go-mutesting |

## Regras de seguranÃ§a
- âœ… Testes nunca devem conter dados reais de produÃ§Ã£o
- âœ… Fixtures devem usar dados sintÃ©ticos (faker, factory)
- âŒ Nunca desabilitar testes que falham â€” investigar e corrigir
- âŒ Nunca testar contra APIs de produÃ§Ã£o (usar mocks ou staging)
